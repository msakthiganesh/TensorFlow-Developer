{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of C2_W1_Assignment.ipynb","provenance":[{"file_id":"https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/25_august_2021_fixes/C2/W1/assignment/C2_W1_Assignment.ipynb","timestamp":1642699116522}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"id":"zX4Kg8DUTKWO","executionInfo":{"status":"ok","timestamp":1642858000004,"user_tz":-330,"elapsed":649,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5uopMdO9Tq7U"},"source":["**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Click the button on top that says, `Open in Colab`, to run this notebook as a Colab. Running the notebook on your local machine might result in some of the code blocks throwing errors."]},{"cell_type":"code","metadata":{"id":"dn-6c02VmqiN","executionInfo":{"status":"ok","timestamp":1642858002915,"user_tz":-330,"elapsed":2368,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}}},"source":["# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\n","# This will require you doing a lot of data preprocessing because\n","# the dataset isn't split into training and validation for you\n","# This code block has all the required inputs\n","import os\n","import zipfile\n","import random\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from shutil import copyfile"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"3sd9dQWa23aj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642858019060,"user_tz":-330,"elapsed":16151,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}},"outputId":"26394bb3-6a53-4413-f764-360e4be12797"},"source":["# This code block downloads the full Cats-v-Dogs dataset and stores it as \n","# cats-and-dogs.zip. It then unzips it to /tmp\n","# which will create a tmp/PetImages directory containing subdirectories\n","# called 'Cat' and 'Dog' (that's how the original researchers structured it)\n","# If the URL doesn't work, \n","# .   visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n","# And right click on the 'Download Manually' link to get a new URL\n","\n","!wget --no-check-certificate \\\n","    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n","    -O \"/tmp/cats-and-dogs.zip\"\n","\n","local_zip = '/tmp/cats-and-dogs.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp')\n","zip_ref.close()\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-22 13:26:42--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n","Resolving download.microsoft.com (download.microsoft.com)... 72.246.252.126, 2600:1402:2000:1bb::e59, 2600:1402:2000:193::e59\n","Connecting to download.microsoft.com (download.microsoft.com)|72.246.252.126|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 824894548 (787M) [application/octet-stream]\n","Saving to: ‘/tmp/cats-and-dogs.zip’\n","\n","/tmp/cats-and-dogs. 100%[===================>] 786.68M   193MB/s    in 4.2s    \n","\n","2022-01-22 13:26:46 (189 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"gi3yD62a6X3S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642858019061,"user_tz":-330,"elapsed":26,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}},"outputId":"5f6ba329-1301-4bda-9ea1-e245fcc1f0ad"},"source":["print(len(os.listdir('/tmp/PetImages/Cat/')))\n","print(len(os.listdir('/tmp/PetImages/Dog/')))\n","\n","# Expected Output:\n","# 12501\n","# 12501"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["12501\n","12501\n"]}]},{"cell_type":"code","metadata":{"id":"F-QkLjxpmyK2","executionInfo":{"status":"ok","timestamp":1642858019061,"user_tz":-330,"elapsed":21,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}}},"source":["# Use os.mkdir to create your directories\n","# You will need a directory for cats-v-dogs, and subdirectories for training\n","# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n","try:\n","    classes = ['cats','dogs']\n","  \n","    for class_name in classes:\n","      ### START CODE HERE\n","        os.makedirs(os.path.join('/tmp/cats-v-dogs/training/', class_name), exist_ok=True)\n","        os.makedirs(os.path.join('/tmp/cats-v-dogs/testing/', class_name), exist_ok=True)\n","      ### END CODE HERE\n","except OSError:\n","    pass"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvSODo0f9LaU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642858034090,"user_tz":-330,"elapsed":15049,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}},"outputId":"a3d45991-d3d8-4d1a-d0d2-2cf774fe07b7"},"source":["# Write a python function called split_data which takes\n","# a SOURCE directory containing the files\n","# a TRAINING directory that a portion of the files will be copied to\n","# a TESTING directory that a portion of the files will be copie to\n","# a SPLIT SIZE to determine the portion\n","# The files should also be randomized, so that the training set is a random\n","# X% of the files, and the test set is the remaining files\n","# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n","# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n","# and 10% of the images will be copied to the TESTING dir\n","# Also -- All images should be checked, and if they have a zero file length,\n","# they will not be copied over\n","#\n","# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n","# os.path.getsize(PATH) gives you the size of the file\n","# copyfile(source, destination) copies a file from source to destination\n","# random.sample(list, len(list)) shuffles a list\n","def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n","  \n","  ### START CODE HERE\n","  file_list = os.listdir(SOURCE)\n","\n","  for f in file_list:\n","    if os.path.getsize(os.path.join(SOURCE, f)) == 0:\n","      print(f'{f} is zero length, so ignoring')\n","      file_list.remove(f) \n","\n","  training_list = random.sample(file_list, len(file_list))[:int(SPLIT_SIZE * len(file_list))]\n","  testing_list = random.sample(file_list, len(file_list))[int(SPLIT_SIZE * len(file_list)):]\n","\n","  for f in training_list:\n","      copyfile(os.path.join(SOURCE, f), os.path.join(TRAINING, f)) \n","  \n","  for f in testing_list:\n","      copyfile(os.path.join(SOURCE, f), os.path.join(TESTING, f))\n","  \n","  ### END CODE HERE\n","\n","\n","CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n","TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n","TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n","DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n","TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n","TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n","\n","split_size = .9\n","split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n","split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n","\n","# Expected output\n","# 666.jpg is zero length, so ignoring\n","# 11702.jpg is zero length, so ignoring"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["666.jpg is zero length, so ignoring\n","11702.jpg is zero length, so ignoring\n"]}]},{"cell_type":"code","metadata":{"id":"luthalB76ufC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642858034094,"user_tz":-330,"elapsed":29,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}},"outputId":"210e4139-df5d-431d-f8c8-1c019b7294d5"},"source":["print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n","print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n","print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n","print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n","\n","# Expected output:\n","# 11250\n","# 11250\n","# 1250\n","# 1250"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["12500\n","12500\n","6601\n","6509\n"]}]},{"cell_type":"code","source":["import cv2"],"metadata":{"id":"J8FmaXv3oHup","executionInfo":{"status":"ok","timestamp":1642858034095,"user_tz":-330,"elapsed":25,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["img = cv2.imread('/tmp/cats-v-dogs/training/dogs/0.jpg')"],"metadata":{"id":"1yfZ5tJ0oR_3","executionInfo":{"status":"ok","timestamp":1642858034097,"user_tz":-330,"elapsed":26,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["img.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BY5f5bmdohXs","executionInfo":{"status":"ok","timestamp":1642858034098,"user_tz":-330,"elapsed":27,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}},"outputId":"0b2e52b3-de27-47c2-a1f3-93f13e192f54"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(375, 500, 3)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"-BQrav4anTmj","executionInfo":{"status":"ok","timestamp":1642858040367,"user_tz":-330,"elapsed":6293,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}}},"source":["# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n","# USE AT LEAST 3 CONVOLUTION LAYERS\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlNjoJ5D61N6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642858040795,"user_tz":-330,"elapsed":446,"user":{"displayName":"Sakthi Ganesh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggo7am_vSe3LQzhxYLNcakgVMFom8e1cy0Y6EMcz6c=s64","userId":"01084309548774252677"}},"outputId":"dc463296-7c1e-4d5e-e760-fec5ac6e3575"},"source":["TRAINING_DIR = '/tmp/cats-v-dogs/training/'\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","train_generator = train_datagen.flow_from_directory(\n","    TRAINING_DIR,\n","    batch_size=20,\n","    class_mode = 'binary',\n","    target_size=(150, 150)\n",")\n","\n","VALIDATION_DIR = '/tmp/cats-v-dogs/testing/'\n","validation_datagen = ImageDataGenerator(rescale=1/255.)\n","validation_generator = validation_datagen.flow_from_directory(\n","    VALIDATION_DIR,\n","    batch_size=20,\n","    class_mode='binary',\n","    target_size=(150, 150)\n",")\n","\n","# Expected Output:\n","# Found 22498 images belonging to 2 classes.\n","# Found 2500 images belonging to 2 classes."],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 24998 images belonging to 2 classes.\n","Found 13109 images belonging to 2 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"t0DhZbH3CDGi"},"source":["Note: You can ignore the `UserWarning: Possibly corrupt EXIF data.` warnings."]},{"cell_type":"code","metadata":{"id":"KyS4n53w7DxC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a76b647b-612c-4d42-f22b-95ef4c929fa1"},"source":["history = model.fit(train_generator,\n","                              epochs=50,\n","                              verbose=1,\n","                              validation_data=validation_generator)\n","\n","# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation\n","# i.e. acc:A1 and val_acc:A2 will be visible, and both A1 and A2 will be > .9"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"," 353/1250 [=======>......................] - ETA: 1:07 - loss: 0.6761 - accuracy: 0.5684"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n","  warnings.warn(str(msg))\n"]},{"output_type":"stream","name":"stdout","text":["1250/1250 [==============================] - 140s 108ms/step - loss: 0.6061 - accuracy: 0.6546 - val_loss: 0.5337 - val_accuracy: 0.7419\n","Epoch 2/50\n","1250/1250 [==============================] - 135s 108ms/step - loss: 0.5063 - accuracy: 0.7515 - val_loss: 0.4567 - val_accuracy: 0.7982\n","Epoch 3/50\n","1250/1250 [==============================] - 134s 107ms/step - loss: 0.4531 - accuracy: 0.7861 - val_loss: 0.4326 - val_accuracy: 0.8005\n","Epoch 4/50\n","1250/1250 [==============================] - 135s 108ms/step - loss: 0.4140 - accuracy: 0.8098 - val_loss: 0.3900 - val_accuracy: 0.8339\n","Epoch 5/50\n","1250/1250 [==============================] - 134s 107ms/step - loss: 0.3848 - accuracy: 0.8266 - val_loss: 0.3499 - val_accuracy: 0.8532\n","Epoch 6/50\n","1250/1250 [==============================] - 134s 107ms/step - loss: 0.3595 - accuracy: 0.8399 - val_loss: 0.3171 - val_accuracy: 0.8657\n","Epoch 7/50\n","1250/1250 [==============================] - 136s 109ms/step - loss: 0.3404 - accuracy: 0.8509 - val_loss: 0.3459 - val_accuracy: 0.8456\n","Epoch 8/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.3227 - accuracy: 0.8608 - val_loss: 0.2997 - val_accuracy: 0.8693\n","Epoch 9/50\n","1250/1250 [==============================] - 137s 109ms/step - loss: 0.3073 - accuracy: 0.8671 - val_loss: 0.2946 - val_accuracy: 0.8754\n","Epoch 10/50\n","1250/1250 [==============================] - 135s 108ms/step - loss: 0.2921 - accuracy: 0.8758 - val_loss: 0.2342 - val_accuracy: 0.9101\n","Epoch 11/50\n","1250/1250 [==============================] - 136s 109ms/step - loss: 0.2802 - accuracy: 0.8821 - val_loss: 0.3356 - val_accuracy: 0.8482\n","Epoch 12/50\n","1250/1250 [==============================] - 136s 108ms/step - loss: 0.2634 - accuracy: 0.8919 - val_loss: 0.2230 - val_accuracy: 0.9193\n","Epoch 13/50\n","1250/1250 [==============================] - 136s 109ms/step - loss: 0.2546 - accuracy: 0.8942 - val_loss: 0.2024 - val_accuracy: 0.9281\n","Epoch 14/50\n","1250/1250 [==============================] - 137s 109ms/step - loss: 0.2430 - accuracy: 0.9026 - val_loss: 0.2098 - val_accuracy: 0.9299\n","Epoch 15/50\n","1250/1250 [==============================] - 136s 109ms/step - loss: 0.2344 - accuracy: 0.9038 - val_loss: 0.2050 - val_accuracy: 0.9360\n","Epoch 16/50\n","1250/1250 [==============================] - 134s 107ms/step - loss: 0.2260 - accuracy: 0.9116 - val_loss: 0.1977 - val_accuracy: 0.9442\n","Epoch 17/50\n","1250/1250 [==============================] - 134s 107ms/step - loss: 0.2149 - accuracy: 0.9136 - val_loss: 0.2134 - val_accuracy: 0.9201\n","Epoch 18/50\n","1250/1250 [==============================] - 135s 108ms/step - loss: 0.2108 - accuracy: 0.9166 - val_loss: 0.1545 - val_accuracy: 0.9512\n","Epoch 19/50\n","1250/1250 [==============================] - 136s 109ms/step - loss: 0.2019 - accuracy: 0.9208 - val_loss: 0.1490 - val_accuracy: 0.9583\n","Epoch 20/50\n","1250/1250 [==============================] - 138s 110ms/step - loss: 0.1957 - accuracy: 0.9251 - val_loss: 0.1620 - val_accuracy: 0.9590\n","Epoch 21/50\n","1250/1250 [==============================] - 138s 110ms/step - loss: 0.1867 - accuracy: 0.9280 - val_loss: 0.1551 - val_accuracy: 0.9677\n","Epoch 22/50\n","1250/1250 [==============================] - 137s 110ms/step - loss: 0.1820 - accuracy: 0.9268 - val_loss: 0.1552 - val_accuracy: 0.9622\n","Epoch 23/50\n","1250/1250 [==============================] - 135s 108ms/step - loss: 0.1794 - accuracy: 0.9319 - val_loss: 0.2651 - val_accuracy: 0.9313\n","Epoch 24/50\n","1250/1250 [==============================] - 136s 109ms/step - loss: 0.1768 - accuracy: 0.9339 - val_loss: 0.2023 - val_accuracy: 0.9639\n","Epoch 25/50\n","1250/1250 [==============================] - 135s 108ms/step - loss: 0.1714 - accuracy: 0.9363 - val_loss: 0.3201 - val_accuracy: 0.8762\n","Epoch 26/50\n","1250/1250 [==============================] - 135s 108ms/step - loss: 0.1631 - accuracy: 0.9380 - val_loss: 0.1574 - val_accuracy: 0.9693\n","Epoch 27/50\n","1250/1250 [==============================] - 135s 108ms/step - loss: 0.1611 - accuracy: 0.9397 - val_loss: 0.1841 - val_accuracy: 0.9693\n","Epoch 28/50\n","1250/1250 [==============================] - 138s 111ms/step - loss: 0.1656 - accuracy: 0.9401 - val_loss: 0.1726 - val_accuracy: 0.9595\n","Epoch 29/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1617 - accuracy: 0.9409 - val_loss: 0.2661 - val_accuracy: 0.9124\n","Epoch 30/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1631 - accuracy: 0.9410 - val_loss: 0.2815 - val_accuracy: 0.8971\n","Epoch 31/50\n","1250/1250 [==============================] - 141s 113ms/step - loss: 0.1602 - accuracy: 0.9434 - val_loss: 0.2204 - val_accuracy: 0.9411\n","Epoch 32/50\n","1250/1250 [==============================] - 143s 114ms/step - loss: 0.1617 - accuracy: 0.9412 - val_loss: 0.2131 - val_accuracy: 0.9627\n","Epoch 33/50\n","1250/1250 [==============================] - 144s 115ms/step - loss: 0.1601 - accuracy: 0.9430 - val_loss: 0.1910 - val_accuracy: 0.9654\n","Epoch 34/50\n","1250/1250 [==============================] - 142s 113ms/step - loss: 0.1627 - accuracy: 0.9405 - val_loss: 0.1782 - val_accuracy: 0.9548\n","Epoch 35/50\n","1250/1250 [==============================] - 142s 114ms/step - loss: 0.1606 - accuracy: 0.9415 - val_loss: 0.1533 - val_accuracy: 0.9712\n","Epoch 36/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1656 - accuracy: 0.9396 - val_loss: 0.2608 - val_accuracy: 0.9230\n","Epoch 37/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1616 - accuracy: 0.9421 - val_loss: 0.1938 - val_accuracy: 0.9578\n","Epoch 38/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1696 - accuracy: 0.9411 - val_loss: 0.1834 - val_accuracy: 0.9571\n","Epoch 39/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1696 - accuracy: 0.9378 - val_loss: 0.2638 - val_accuracy: 0.9154\n","Epoch 40/50\n","1250/1250 [==============================] - 138s 110ms/step - loss: 0.1703 - accuracy: 0.9392 - val_loss: 0.2245 - val_accuracy: 0.9518\n","Epoch 41/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1750 - accuracy: 0.9400 - val_loss: 0.2570 - val_accuracy: 0.9190\n","Epoch 42/50\n","1250/1250 [==============================] - 138s 110ms/step - loss: 0.1793 - accuracy: 0.9350 - val_loss: 0.1664 - val_accuracy: 0.9599\n","Epoch 43/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1870 - accuracy: 0.9332 - val_loss: 0.2357 - val_accuracy: 0.9497\n","Epoch 44/50\n","1250/1250 [==============================] - 139s 111ms/step - loss: 0.1838 - accuracy: 0.9348 - val_loss: 0.3312 - val_accuracy: 0.8448\n","Epoch 45/50\n","1250/1250 [==============================] - 141s 113ms/step - loss: 0.1880 - accuracy: 0.9352 - val_loss: 0.2057 - val_accuracy: 0.9439\n","Epoch 46/50\n","1250/1250 [==============================] - 140s 112ms/step - loss: 0.1854 - accuracy: 0.9321 - val_loss: 0.2881 - val_accuracy: 0.8989\n","Epoch 47/50\n","1250/1250 [==============================] - 139s 112ms/step - loss: 0.1892 - accuracy: 0.9338 - val_loss: 0.3242 - val_accuracy: 0.8834\n","Epoch 48/50\n"," 605/1250 [=============>................] - ETA: 51s - loss: 0.1764 - accuracy: 0.9353"]}]},{"cell_type":"code","metadata":{"id":"MWZrJN4-65RC"},"source":["# PLOT LOSS AND ACCURACY\n","%matplotlib inline\n","\n","import matplotlib.image  as mpimg\n","import matplotlib.pyplot as plt\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","epochs=range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n","plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n","plt.title('Training and validation accuracy')\n","plt.figure()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot(epochs, loss, 'r', \"Training Loss\")\n","plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n","\n","\n","plt.title('Training and validation loss')\n","\n","# Desired output. Charts with training and validation metrics. No crash :)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hz4OGHRqTu34"},"source":["**Important Note:** Due to some compatibility issues, the following code block will result in an error after you select the images(s) to upload if you are running this notebook as a `Colab` on the `Safari` browser. For `all other broswers`, continue with the next code block and ignore the next one after it.\n","\n","The ones running the `Colab` on `Safari`, comment out the code block below, uncomment the next code block and run it."]},{"cell_type":"code","metadata":{"id":"LqL6FYUrtXpf"},"source":["# Here's a codeblock just for fun. You should be able to upload an image here \n","# and have it classified without crashing\n","\n","import numpy as np\n","from google.colab import files\n","from keras.preprocessing import image\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n"," \n","  # predicting images\n","  path = '/content/' + fn\n","  img = image.load_img(path, target_size=(# YOUR CODE HERE))\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","\n","  images = np.vstack([x])\n","  classes = model.predict(images, batch_size=10)\n","  print(classes[0])\n","  if classes[0]>0.5:\n","    print(fn + \" is a dog\")\n","  else:\n","    print(fn + \" is a cat\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JCedp9jpT1lV"},"source":["For those running this `Colab` on `Safari` broswer can upload the images(s) manually. Follow the instructions, uncomment the code block below and run it.\n","\n","Instructions on how to upload image(s) manually in a Colab:\n","\n","1. Select the `folder` icon on the left `menu bar`.\n","2. Click on the `folder with an arrow pointing upwards` named `..`\n","3. Click on the `folder` named `tmp`.\n","4. Inside of the `tmp` folder, `create a new folder` called `images`. You'll see the `New folder` option by clicking the `3 vertical dots` menu button next to the `tmp` folder.\n","5. Inside of the new `images` folder, upload an image(s) of your choice, preferably of either a horse or a human. Drag and drop the images(s) on top of the `images` folder.\n","6. Uncomment and run the code block below. "]},{"cell_type":"code","metadata":{"id":"tIIVadyNT1YZ"},"source":["# import numpy as np\n","# from keras.preprocessing import image\n","# import os\n","\n","# images = os.listdir(\"/tmp/images\")\n","\n","# print(images)\n","\n","# for i in images:\n","#  print()\n","#  # predicting images\n","#  path = '/tmp/images/' + i\n","#  img = image.load_img(path, target_size=(150, 150))\n","#  x = image.img_to_array(img)\n","#  x = np.expand_dims(x, axis=0)\n","\n","#  images = np.vstack([x])\n","#  classes = model.predict(images, batch_size=10)\n","#  print(classes[0])\n","#  if classes[0]>0.5:\n","#    print(i + \" is a dog\")\n","#  else:\n","#    print(i + \" is a cat\")"],"execution_count":null,"outputs":[]}]}